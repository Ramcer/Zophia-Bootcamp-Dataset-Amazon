{"cells": [{"cell_type": "code", "execution_count": 100, "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark import SparkContext\nspark = SparkSession.builder \\\n  .appName('clean_external_products') \\\n  .config('spark.jars', 'gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar') \\\n  .getOrCreate()"}, {"cell_type": "code", "execution_count": 101, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- app_sale_price: double (nullable = true)\n |-- app_sale_price_currency: string (nullable = true)\n |-- country: string (nullable = true)\n |-- evaluate_rate: string (nullable = true)\n |-- isbestseller: boolean (nullable = true)\n |-- isprime: boolean (nullable = true)\n |-- original_price: string (nullable = true)\n |-- product_detail_url: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- product_main_image_url: string (nullable = true)\n |-- product_title: string (nullable = true)\n\n"}], "source": "table = \"becade_rgarciaf.stg_external_procuts\"\nexternal_products = spark.read \\\n  .format(\"bigquery\") \\\n  .option(\"table\", table) \\\n  .load()\n\nexternal_products.printSchema()"}, {"cell_type": "code", "execution_count": 103, "metadata": {}, "outputs": [], "source": "import pandas as pd"}, {"cell_type": "code", "execution_count": 104, "metadata": {}, "outputs": [], "source": "external_products_2 = external_products.toPandas()"}, {"cell_type": "code", "execution_count": 105, "metadata": {}, "outputs": [], "source": "def clean_currency(data):\n    for i in data.index:\n            if((data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and (data[\"country\"][i]==\"US\" or data[\"country\"][i]==\"AU\" or data[\"country\"][i]==\"CA\")):\n                data[\"app_sale_price_currency\"][i]=\"$\"\n\n            if( (data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and data[\"country\"][i]==\"BR\"):\n                data[\"app_sale_price_currency\"][i]=\"R$\"\n\n            if((data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and (data[\"country\"][i]==\"FR\" or data[\"country\"][i]==\"DE\" or data[\"country\"][i]==\"IT\" or data[\"country\"][i]==\"NL\" or data[\"country\"][i]==\"ES\")):\n                data[\"app_sale_price_currency\"][i]=\"\u20ac\"\n\n            if((data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and data[\"country\"][i]==\"IN\"):\n                data[\"app_sale_price_currency\"][i]=\"\u20b9\"\n\n            if((data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and data[\"country\"][i]==\"TR\"):\n                data[\"app_sale_price_currency\"][i]=\"TL\"\n\n            if((data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and data[\"country\"][i]==\"AE\"):\n                data[\"app_sale_price_currency\"][i]=\"AED\"\n\n            if((data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and data[\"country\"][i]==\"GB\"):\n                data[\"app_sale_price_currency\"][i]=\"\u00a3\"\n\n            if((data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and data[\"country\"][i]==\"JP\"):\n                data[\"app_sale_price_currency\"][i]=\"\u00a5\"\n\n            if((data[\"app_sale_price_currency\"][i]=='' or data[\"app_sale_price_currency\"][i]==None) and data[\"country\"][i]==\"SG\"):\n                data[\"app_sale_price_currency\"][i]=\"S$\"\n\n    print('Added missing currencies')\n    return data"}, {"cell_type": "code", "execution_count": 106, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/opt/conda/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n"}, {"name": "stdout", "output_type": "stream", "text": "Added missing currencies\n"}], "source": "external_products_2 = clean_currency(external_products_2)"}, {"cell_type": "code", "execution_count": 107, "metadata": {}, "outputs": [], "source": "table_tasas = \"becade_rgarciaf.stg_tasas_cambio_pais_anual \"\ntasas = spark.read \\\n  .format(\"bigquery\") \\\n  .option(\"table\", table_tasas) \\\n  .load()"}, {"cell_type": "code", "execution_count": 108, "metadata": {}, "outputs": [], "source": "tasas_pd = tasas.toPandas()"}, {"cell_type": "code", "execution_count": 109, "metadata": {}, "outputs": [], "source": "def generate_app_price_us(data,tasas):\n    products_standard_price = {'isbestseller': [] , 'product_id': [] ,'app_sale_price': [], 'app_sale_price_currency': [],'isprime' : [],'evaluate_rate':[],'country':[],'app_sale_price_us':[]}  \n    data_sale_price_us=0\n    for i in data.index:\n        if(data['country'][i]==\"US\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])*1)\n\n        if(data['country'][i]==\"AU\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])/float(tasas_pd.loc[((tasas_pd['currency_year'] == 2020) & (tasas_pd['Country_name'] == 'Australia'))]['value']))\n\n        if(data['country'][i]==\"CA\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])/float(tasas_pd.loc[((tasas_pd['currency_year'] == 2020) & (tasas_pd['Country_name'] == 'Canada'))]['value']))\n\n        if(data['country'][i]==\"BR\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])/float(tasas_pd.loc[((tasas_pd['currency_year'] == 2020) & (tasas_pd['Country_name'] == 'Brazil'))]['value']))\n\n        if(data['country'][i]==\"FR\" or data['country'][i]==\"DE\" or data['country'][i]==\"IT\" or data['country'][i]==\"NL\" or data['country'][i]==\"ES\" ):\n            data_sale_price_us= (float(data['app_sale_price'][i])/float(tasas_pd.loc[((tasas_pd['currency_year'] == 2020) & (tasas_pd['Country_name'] == 'Germany') & (tasas_pd['currency'] == 'EUR'))]['value']))\n\n        if(data['country'][i]==\"IN\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])/float(tasas_pd.loc[((tasas_pd['currency_year'] == 2020) & (tasas_pd['Country_name'] == 'India'))]['value']))\n\n        if(data['country'][i]==\"TR\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])/float(tasas_pd.loc[((tasas_pd['currency_year'] == 2020) & (tasas_pd['Country_name'] == 'Turkey'))]['value']))\n\n        if(data['country'][i]==\"AE\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])/0.27)\n\n        if(data['country'][i]==\"GB\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])/float(tasas_pd.loc[((tasas_pd['currency_year'] == 2020) & (tasas_pd['Country_name'] == 'United Kingdom'))]['value']))\n\n        if(data['country'][i]==\"JP\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])/float(tasas_pd.loc[((tasas_pd['currency_year'] == 2020) & (tasas_pd['Country_name'] == 'Japan'))]['value']))\n\n        if(data['country'][i]==\"SG\"):\n            data_sale_price_us= (float(data['app_sale_price'][i])*0.74)\n            \n        products_standard_price['isbestseller'].append(data['isbestseller'][i])\n        products_standard_price['product_id'].append(data['product_id'][i])\n        products_standard_price['app_sale_price'].append(data['app_sale_price'][i])\n        products_standard_price['app_sale_price_currency'].append(data['app_sale_price_currency'][i])\n        products_standard_price['isprime'].append(data['isprime'][i])\n        products_standard_price['evaluate_rate'].append(data['evaluate_rate'][i])\n        products_standard_price['country'].append(data['country'][i])\n        products_standard_price['app_sale_price_us'].append(data_sale_price_us)\n\n    return products_standard_price\n\n"}, {"cell_type": "code", "execution_count": 110, "metadata": {}, "outputs": [], "source": "external_products_standard_price = pd.DataFrame(generate_app_price_us(external_products_2,tasas_pd))"}, {"cell_type": "code", "execution_count": 111, "metadata": {}, "outputs": [], "source": "external_products_standard_price_spark=spark.createDataFrame(external_products_standard_price) "}, {"cell_type": "code", "execution_count": 112, "metadata": {}, "outputs": [], "source": "external_products_standard_price_spark_2=external_products_standard_price_spark.withColumn(\"app_sale_price\",external_products_standard_price_spark.app_sale_price.cast(\"decimal(10,2)\")) \\\n    .withColumn(\"app_sale_price_us\",external_products_standard_price_spark.app_sale_price_us.cast(\"decimal(10,2)\"))"}, {"cell_type": "code", "execution_count": 114, "metadata": {}, "outputs": [], "source": "external_products_standard_price_spark_2.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\",\"becade_rgarciaf.external_products_standard_price\") \\\n  .option(\"temporaryGcsBucket\", \"amazon_bucket_ramiro\") \\\n  .mode('overwrite') \\\n  .save()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "################################ 2 ##############################"}, {"cell_type": "code", "execution_count": 115, "metadata": {}, "outputs": [], "source": "from pyspark.sql.functions import sum, col, desc, avg, count, countDistinct"}, {"cell_type": "code", "execution_count": 116, "metadata": {}, "outputs": [], "source": "external_products_avg_price = external_products_standard_price_spark_2.groupBy(\"product_id\").agg(avg(\"app_sale_price_us\").alias(\"avg_price_us\"),countDistinct(\"country\").alias(\"count_country\")) "}, {"cell_type": "code", "execution_count": 117, "metadata": {}, "outputs": [], "source": "external_products_avg_price.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\",\"becade_rgarciaf.external_products_avg_price\") \\\n  .option(\"temporaryGcsBucket\", \"amazon_bucket_ramiro\") \\\n  .mode('overwrite') \\\n  .save()"}, {"cell_type": "code", "execution_count": 118, "metadata": {}, "outputs": [], "source": "########################## 3 #########################"}, {"cell_type": "code", "execution_count": 119, "metadata": {}, "outputs": [], "source": "external_products_id=external_products_standard_price_spark_2.select(\"product_id\").distinct()"}, {"cell_type": "code", "execution_count": 120, "metadata": {}, "outputs": [], "source": "external_products_standard_price_spark_2=external_products_standard_price_spark.withColumn(\"app_sale_price\",external_products_standard_price_spark.app_sale_price.cast(\"float\")) \\\n    .withColumn(\"app_sale_price_us\",external_products_standard_price_spark.app_sale_price_us.cast(\"float\"))"}, {"cell_type": "code", "execution_count": 121, "metadata": {}, "outputs": [], "source": "external_products_id_pd=external_products_id.toPandas()\nexternal_products_standard_price_pd = external_products_standard_price_spark_2.toPandas()"}, {"cell_type": "code", "execution_count": 122, "metadata": {}, "outputs": [], "source": "def find_max_and_min(data,product_id):\n    print(\"arrancando con todaaaaa\")\n    products_price_ranges = {'product_id': [] ,'max_price': [], 'max_country': [],'min_price' : [],'min_country':[]}  \n    max_country=''\n    max_price=0\n    min_price=10000000000\n    min_country=''\n    j=0\n    for product in product_id['product_id']:\n        if(j%100==0):\n            print(j)\n        for i in data.index:\n            if (data[\"product_id\"][i]==product):\n                if max_price < data[\"app_sale_price_us\"][i]:\n                    max_price=data[\"app_sale_price_us\"][i]\n                    max_country = data[\"country\"][i]\n                if min_price > data[\"app_sale_price_us\"][i]:\n                    min_price=data[\"app_sale_price_us\"][i]\n                    min_country = data[\"country\"][i]\n        products_price_ranges['product_id'].append(product)\n        products_price_ranges['max_price'].append(max_price)\n        products_price_ranges['max_country'].append(max_country)\n        products_price_ranges['min_price'].append(min_price)\n        products_price_ranges['min_country'].append(min_country)\n        j=j+1\n        max_price=0\n        max_country=''\n        min_price=10000000000\n        min_country=''\n    return products_price_ranges"}, {"cell_type": "code", "execution_count": 123, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "arrancando con todaaaaa\n0\n100\n200\n300\n400\n500\n600\n700\n800\n900\n1000\n1100\n1200\n1300\n1400\n1500\n1600\n1700\n1800\n1900\n2000\n2100\n2200\n2300\n2400\n2500\n2600\n2700\n2800\n2900\n3000\n3100\n3200\n3300\n3400\n3500\n3600\n3700\n3800\n3900\n4000\n4100\n4200\n4300\n4400\n4500\n4600\n4700\n4800\n4900\n5000\n5100\n5200\n5300\n5400\n5500\n5600\n5700\n5800\n5900\n6000\n6100\n6200\n6300\n6400\n6500\n6600\n"}], "source": "external_products_standard_price = find_max_and_min(external_products_standard_price_pd,external_products_id_pd)"}, {"cell_type": "code", "execution_count": 124, "metadata": {}, "outputs": [], "source": "external_products_price_range_pd=pd.DataFrame(external_products_standard_price)"}, {"cell_type": "code", "execution_count": 125, "metadata": {}, "outputs": [], "source": "external_products_price_ranges_spark=spark.createDataFrame(external_products_price_range_pd) \n"}, {"cell_type": "code", "execution_count": 126, "metadata": {}, "outputs": [], "source": "external_products_price_ranges_spark_2=external_products_price_ranges_spark.withColumn(\"max_price\",external_products_price_ranges_spark.max_price.cast(\"decimal(10,2)\")) \\\n    .withColumn(\"min_price\",external_products_price_ranges_spark.min_price.cast(\"decimal(10,2)\"))"}, {"cell_type": "code", "execution_count": 127, "metadata": {}, "outputs": [], "source": "external_products_price_ranges_spark_2.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\",\"becade_rgarciaf.external_products_price_range\") \\\n  .option(\"temporaryGcsBucket\", \"amazon_bucket_ramiro\") \\\n  .mode('overwrite') \\\n  .save()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "####################################################### 4 #######################################################"}, {"cell_type": "code", "execution_count": 128, "metadata": {}, "outputs": [], "source": "table_standar_price = \"becade_rgarciaf.external_products_standard_price \"\nexternal_standar_price = spark.read \\\n  .format(\"bigquery\") \\\n  .option(\"table\", table_standar_price) \\\n  .load()"}, {"cell_type": "code", "execution_count": 129, "metadata": {}, "outputs": [], "source": "external_standar_price_pd=external_standar_price.toPandas()"}, {"cell_type": "code", "execution_count": 130, "metadata": {}, "outputs": [], "source": "def filter_evaluate_range(data):\n    for i in data.index:\n        if(data[\"evaluate_rate\"][i]==\"\" or data[\"evaluate_rate\"][i]==None):\n            data[\"evaluate_rate\"][i]=\"0.0\"\n        data[\"evaluate_rate\"][i] = ''.join((filter(lambda x: x in '0123456789,.', data[\"evaluate_rate\"][i])))\n        if(data[\"evaluate_rate\"][i].count('5') >1 ):\n            if( data[\"evaluate_rate\"][i][data[\"evaluate_rate\"][i].rfind('5')-1] == ',' or '.' ) :\n                list1= list(data[\"evaluate_rate\"][i])\n                list1[data[\"evaluate_rate\"][i].find('5')]=\"\"\n                data[\"evaluate_rate\"][i]=''.join(list1)\n            if(len(data[\"evaluate_rate\"][i]) > (data[\"evaluate_rate\"][i].find('5')+1) ):\t\n                if (data[\"evaluate_rate\"][i][data[\"evaluate_rate\"][i].find('5')+1] ==  ',' or '.' ) :\n                    list1 = list(data[\"evaluate_rate\"][i])\n                    list1[data[\"evaluate_rate\"][i].rfind('5')]=\"\"\n                    data[\"evaluate_rate\"][i]=''.join(list1)\n        else:\n            data[\"evaluate_rate\"][i] = ''.join((filter(lambda x: x not in '5', data[\"evaluate_rate\"][i])))\n        data[\"evaluate_rate\"][i]=data[\"evaluate_rate\"][i].replace(\",\",\".\")\n\n    return data"}, {"cell_type": "code", "execution_count": 131, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/opt/conda/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"\n/opt/conda/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  # Remove the CWD from sys.path while we load stuff.\n/opt/conda/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n"}], "source": "external_standar_price_pd_filtered= filter_evaluate_range(external_standar_price_pd)"}, {"cell_type": "code", "execution_count": 132, "metadata": {}, "outputs": [], "source": "external_standar_price_spark_filtered=spark.createDataFrame(external_standar_price_pd_filtered) "}, {"cell_type": "code", "execution_count": 133, "metadata": {}, "outputs": [], "source": "from pyspark.sql.functions import sum, col, desc, avg, count"}, {"cell_type": "code", "execution_count": 134, "metadata": {}, "outputs": [], "source": "external_product_rate_avg=external_standar_price_spark_filtered.groupBy(\"product_id\")\\\n    .agg(avg(\"evaluate_rate\").alias(\"avg_evaluation_rate\"),count(\"country\").alias(\"country_count\"))"}, {"cell_type": "code", "execution_count": 135, "metadata": {}, "outputs": [], "source": "external_product_rate_avg_2 = external_product_rate_avg.withColumn(\"avg_evaluation_rate\",external_product_rate_avg.avg_evaluation_rate.cast(\"decimal(10,2)\"))"}, {"cell_type": "code", "execution_count": 136, "metadata": {}, "outputs": [], "source": "external_product_rate_avg_2.write \\\n  .format(\"bigquery\") \\\n  .option(\"table\",\"becade_rgarciaf.external_product_rate_avg\") \\\n  .option(\"temporaryGcsBucket\", \"amazon_bucket_ramiro\") \\\n  .mode('overwrite') \\\n  .save()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}